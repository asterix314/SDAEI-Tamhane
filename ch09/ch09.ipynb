{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0c714a-801d-4de5-96d7-e375584311c7",
   "metadata": {},
   "source": [
    "# Chapter 9 Inferences for Proportions and Count Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77880b95-9144-4d43-9119-3197c2ea4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import polars as pl\n",
    "from polars import col, lit\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97c34b-0e54-4351-97c3-0485d2d5d74e",
   "metadata": {},
   "source": [
    "## 9.1 Inferences on Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594bef62-84fa-4cbf-aa52-aa47f83ab4a1",
   "metadata": {},
   "source": [
    "This chapter begins with inference procedures for an unknown proportion $p$ in a Bernoulli population. The sample proportion $\\hat{p}$ from a random sample of size $n$ is an unbiased estimate of $p$. Inferences on p are based on the central limit theorem (CLT) result that for large $n$, the sample proportion $\\hat{p}$ is approximately normal with mean = $p$ and standard deviation = $\\sqrt{pq/n}$ . A large sample two-sided 100(1- $\\alpha$)% confidence interval for $p$ is given by\n",
    "\n",
    "$$\n",
    "\\left[ \\hat{p} \\pm z_{\\alpha /2} \\sqrt{\\frac{\\hat{p} \\hat{q}}{n}}\\;\\right]\n",
    "$$\n",
    "\n",
    "where $\\hat{q}$ = 1 - $\\hat{p}$ and $z_{\\alpha/2}$ is the upper $\\alpha/2$ critical point of the standard normal distribution. A large sample test on $p$ to test $H_0: p = p_0$ can be based on the test statistic\n",
    "\n",
    "$$\n",
    "z = \\frac{\\hat{p} - p_0}{\\sqrt{\\hat{p}\\hat{q}/n}} \\quad \\text{or} \\quad \n",
    "z = \\frac{\\hat{p} - p_0}{\\sqrt{p_0 q_0 / n}}.\n",
    "$$\n",
    "\n",
    "Both these statistics are asymptotically standard normal under $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0fd2c6-a891-4d89-b524-44e7bde59409",
   "metadata": {},
   "source": [
    "### Ex 9.1\n",
    "\n",
    "A business journal publisher plans to survey a sample of the subscribers to estimate the proportion $p$ with annual household incomes over $100.000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f452e-97e8-4d1d-8601-005a1ef060e8",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "\n",
    "How many subscribers must be surveyed to obtain a 99% CI for $p$ with a margin of error no greater than 0.05? Assume that no prior estimate of $p$ is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8941fac-d57e-42b0-af1c-2e1a647ca879",
   "metadata": {},
   "source": [
    "✍️ The margin of error\n",
    "\n",
    "$$\n",
    "E = z_{\\alpha/2} \\sqrt{\\frac{p q}{n}} \\text{.}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "n = \\frac{z_\\alpha^2 p q}{E^2}\n",
    "$$\n",
    "\n",
    "Because no previous estimate of $p$ is available, we use $1/2$ as a conservative estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e68a7c3-6fae-4f09-bfbf-d78a35dc378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664.0\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.99\n",
    "p = 1/2\n",
    "n = stats.norm.ppf(1-α/2)**2 * p * (1-p)/ 0.05**2\n",
    "print(np.ceil(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d853b9-f03f-4442-95c7-c3542d27d2d3",
   "metadata": {},
   "source": [
    "So 664 subscribers should be serveyed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a65617-5fd9-41d3-8b83-8328f7db5a0b",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "The marketing department thinks that $p$ = 0.30 would be a reasonable guess. What is the corresponding sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740f29e7-5701-47ab-a919-2d7cf6ffcf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558.0\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.99\n",
    "p = 0.3\n",
    "n = stats.norm.ppf(1-α/2)**2 * p * (1-p)/ 0.05**2\n",
    "print(np.ceil(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8c102-0460-41c1-a380-2194415aeefb",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "\n",
    "Refer to the sample size obtained in (b). If a 40% nonresponse rate is anticipated, how many surveys need to be mailed? How may such a high nonresponse rate cause bias in the estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c4b29b-29f9-4b6e-abad-f1fd1026aa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929.0\n"
     ]
    }
   ],
   "source": [
    "non_response_rate = 0.4\n",
    "mails = n / (1 - non_response_rate)\n",
    "print(np.ceil(mails))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932d4f8-1be9-45f0-9c4a-5880fe69363b",
   "metadata": {},
   "source": [
    "Assuming the responses tend to come from higher-income households, the result may overestimate $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ead40d-9985-4da8-bbf2-824531356006",
   "metadata": {},
   "source": [
    "### Ex 9.2\n",
    "\n",
    "While imprisoned by the Germans during World War II, the English mathematician John Kerrich tossed a coin 10,000 times and obtained 5067 heads. Let $p$ be the probability of a head on a single toss. We wish to check if the data are consistent with the hypothesis that the coin was fair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ddeeb-5756-424e-8d18-f53c30a8b491",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "Set up the hypotheses. Why should the alternative be two-sided?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0115af-7434-47ad-a6ed-c48247156d11",
   "metadata": {},
   "source": [
    "✍️\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "H_0: & p = 1/2\\text{, v.s.} \\\\\n",
    "H_1: & p \\ne 1/2 \\text{.}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$H_1$ is two-sided because if the coin is not fair, $p$ could be either $> 1/2$ or $< 1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df40619-adb0-4b4a-8d84-d671774778cd",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "Calculate the $P$-value. Can you reject $H_0$ at the .05 level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "706e1add-3420-4230-b3bd-7da6f4e8ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18024534492890254\n"
     ]
    }
   ],
   "source": [
    "n = 10_000\n",
    "p = 1/2\n",
    "q = 1 - p\n",
    "z = (5067/n - p)/np.sqrt(p*q/n)\n",
    "p_val = 2 * stats.norm.sf(z)\n",
    "print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635266d7-8972-4fe9-9490-de3295befda5",
   "metadata": {},
   "source": [
    "Because 0.18 > 0.05, cannot reject $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb1662-0f39-41ae-ab8a-5ce1c8afc65a",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "Find a 95% CI for the proportion of heads for Kerrich's coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e81bdda3-16ca-4c28-bc4b-80895f9dc3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49690018007729975, 0.5164998199227003)\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.95\n",
    "margin_of_error = float(stats.norm.ppf(1-α/2) * np.sqrt(p*q/n))\n",
    "ci = (5067/n - margin_of_error, 5067/n + margin_of_error)\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa19ce1-6ea4-4d0b-a154-1cd1295b9078",
   "metadata": {},
   "source": [
    "### Ex 9.3\n",
    "\n",
    "Calls to technical support service of a software company are monitored on a sampling basis for quality assurance. Each monitored call is classified as satisfactory or unsatisfactory by the supervisor in terms of the quality of help offered. A random sample of 100 calls was monitored over one month for a new trainee; 8 calls were classified as unsatisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b25caf-0b9c-46e2-a629-edc56fadb6d9",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "Calculate a 95% CI for the actual proportion of unsatisfactory calls during the month.\n",
    "Use both formulas (9.1) and (9.3) and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d2141-096e-41b4-92fa-c141b1122fcd",
   "metadata": {},
   "source": [
    "✍️ Formula (9.1):\n",
    "\n",
    "$$\n",
    "\\hat{p} - z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}\\hat{q}}{n}} \\le p \\le \\hat{p} + z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}\\hat{q}}{n}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6e29646-78f3-496a-a90d-530714b94007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.02682751000723329, 0.1331724899927667)\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.95\n",
    "n = 100\n",
    "p = 8/100\n",
    "q = 1 - p\n",
    "margin_of_error = float(stats.norm.ppf(1-α/2) * np.sqrt(p*q/n))\n",
    "ci = (p - margin_of_error, p + margin_of_error)\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3877f-98c3-4262-bbea-8f67f2efc166",
   "metadata": {},
   "source": [
    "Formula (9.3):\n",
    "\n",
    "$$\n",
    "\\frac{\\hat{p} + \\frac{z^2}{2n} - \\sqrt{\\frac{\\hat{p}\\hat{q}z^2}{n} + \\frac{z^4}{4n^2}}}{1 + \\frac{z^2}{n}} \n",
    "\\le p \\le  \n",
    "\\frac{\\hat{p} + \\frac{z^2}{2n} + \\sqrt{\\frac{\\hat{p}\\hat{q}z^2}{n} + \\frac{z^4}{4n^2}}}{1 + \\frac{z^2}{n}} \n",
    "$$\n",
    "\n",
    "where $z$ = $z_{\\alpha/2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01193ee4-aa9d-4c15-a503-bc0ed0c8f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04109346148438062, 0.14998107700948735)\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.95\n",
    "z = stats.norm.ppf(1-α/2)\n",
    "n = 100\n",
    "p = 8/100\n",
    "q = 1 - p\n",
    "denom = 1 + z**2/n\n",
    "margin = np.sqrt(p*q*z**2/n + z**4/(4*n**2)) / denom\n",
    "mid = (p + z**2/(2*n)) / denom \n",
    "ci = (float(mid - margin), float(mid + margin))\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a40c37-0f2f-4cd1-b91a-e1e4d6cee001",
   "metadata": {},
   "source": [
    "Formula (9.3) gives a slightly higher CI than formula (9.1). (shifts to the right by about 0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c27656-dd92-4e46-b4e7-8d458d32835e",
   "metadata": {},
   "source": [
    "#### (b) \n",
    "This CI is used to test $H_0: p = 0.10$ vs. $H_1: p \\ne 0.10$. If $H_0$ is not rejected, then monitoring of the trainee is continued at the same frequency; if $H_0$ is rejected in the lower tail, then monitoring frequency is reduced; and if $H_0$ is rejected in the upper tail, then the trainee is provided additional training. Based on the CI calculated in (a), what action should be taken on this trainee?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e44d94-1582-40a7-855c-c3bf87c675f3",
   "metadata": {},
   "source": [
    "✍️ Because 0.1 is contained in the CI (for both formulas), $H_0$ is not rejected. Therefore monitoring will continue at the same frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3dda7-cd39-41bf-9c43-740ca6dd02ad",
   "metadata": {},
   "source": [
    "### Ex 9.4\n",
    "\n",
    "The fraction defective in a high volume production process is to be estimated using a 95% CI with a margin of error of 0.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b61cff-1180-4fa7-a964-5bf7ca85920b",
   "metadata": {},
   "source": [
    "#### (a) \n",
    "If the a priori guess at the fraction defective is 1%, how many parts should be sampled? Compare this number with the sample size that you would need if no a priori information regarding the true fraction defective is assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279cd50f-599f-491b-904c-768f51f8c701",
   "metadata": {},
   "source": [
    "✍️ \n",
    "\n",
    "$$\n",
    "n = \\frac{z_\\alpha^2 p q}{E^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce361d22-8951-4814-9250-b660cb60b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9508. 240092.]\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.95\n",
    "p = np.array([0.01, 0.5])\n",
    "n = stats.norm.ppf(1-α/2)**2 * p * (1-p)/ 0.002**2\n",
    "print(np.ceil(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd2eb9-1a12-43ee-9e1d-a34261fc0931",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "One problem with estimating a very low fraction defective is that no defectives may be obtained in the sample, making it impossible to calculate a CI. What sampling method would you use to ensure that there will be sufficient number of defectives in the sample to provide reliable information on the true fraction defective?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8716c6c-b0cf-4528-b86c-fa986ae89558",
   "metadata": {},
   "source": [
    "✍️ Start with a small sample and, if no defectives are found, continue to add to the sample until a certain number of defectives are observed and the current sample provides enough evidence about the proportion of defectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b3c69-ec2b-41ca-8142-073b006e2503",
   "metadata": {},
   "source": [
    "### Ex 9.5\n",
    "\n",
    "A quarterback from a Big Ten college football team worked to improve his proportion of completed passes. His career average had been 46.5% completed passes. His record halfway into the new season is 82 completed passes out of 151 attempted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742fe9d-d22c-4db4-b717-8d353437d17f",
   "metadata": {},
   "source": [
    "#### (a) \n",
    "Set up the hypotheses to test whether his proportion of completed passes has improved. Should the alternative be one-sided or two-sided? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6833b2-4201-44c5-ace1-cd7b3c914c20",
   "metadata": {},
   "source": [
    "✍️ Because we are looking for signs of improvement, one-sided alternative should be used.\n",
    "\n",
    "$$\n",
    "H_0: p = p_0 = 46.5\\% \\quad \\text{v.s.} \\quad H_1: p > p_0 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc6368-33dd-4be4-9ba9-569bd73459d8",
   "metadata": {},
   "source": [
    "#### (b) \n",
    "Perform a test at $\\alpha$ = .05. Is there a significant improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aab3b76-6dc4-4b85-83a0-56fe7aa5fbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027251575849474706\n"
     ]
    }
   ],
   "source": [
    "k, n = 82, 151\n",
    "p0 = 0.465\n",
    "z = (k/n - p0) / np.sqrt(p0*(1-p0)/n)\n",
    "pvalue = stats.norm.sf(z)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e1d50-0381-4c80-93e9-7e4aabb0dff3",
   "metadata": {},
   "source": [
    "Or use the exact, binomial test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73e18d3b-82ee-41f8-9867-aac879f0d345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032948694746468936\n"
     ]
    }
   ],
   "source": [
    "test = stats.binomtest(k=82, n=151, p=0.465, alternative='greater')\n",
    "print(test.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2214cda-b9ef-48f8-934d-da661fe92db7",
   "metadata": {},
   "source": [
    "Both methods result in $p < \\alpha$, so yes, there is significant improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a351f-dbe8-4dcd-9a90-233355cb0dfb",
   "metadata": {},
   "source": [
    "#### (c) \n",
    "At least how many passes out of 151 should he have completed in order to demonstrate significant improvement at $\\alpha$ = .025?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8477b7b-69a8-4de7-ac85-6c35346893b0",
   "metadata": {},
   "source": [
    "✍️ The $z$ statistic should be at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "413cdc21-d939-457b-b156-663cb96a489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.959963984540054\n"
     ]
    }
   ],
   "source": [
    "α = .025\n",
    "z = stats.norm.ppf(1-α)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66480dcf-dd12-4701-ab76-d5c097bdb020",
   "metadata": {},
   "source": [
    "Therefore,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb8e02c7-b887-4d95-9742-a113c2661377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.0\n"
     ]
    }
   ],
   "source": [
    "k = n * (z * np.sqrt(p0*(1-p0)/n) + p0)\n",
    "print(np.ceil(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d61b5-3122-4d39-819a-01a5a5c9f19f",
   "metadata": {},
   "source": [
    "At $\\alpha$ = .025, he should complete 83 passes or more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1294ea-de87-47ec-97b8-2d5ad411cfaf",
   "metadata": {},
   "source": [
    "### Ex 9.6\n",
    "\n",
    "A blood test intended to identify patients at \"high risk\" of cardiac disease gave positive results on 80 out of 100 known cardiac patients, but also on 16 out of 200 known normal patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f610255-540b-4c14-bf13-81cf8adafda4",
   "metadata": {},
   "source": [
    "#### (a) \n",
    "Find a 90% CI for the sensitivity of the test, which is defined as the probability that a cardiac patient is correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc43c4e0-776a-485c-b423-8dd388a44865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7342058549219411, 0.865794145078059)\n"
     ]
    }
   ],
   "source": [
    "α = 1 - 0.9\n",
    "n = 100\n",
    "p = 80/100\n",
    "margin = float(stats.norm.ppf(1-α/2) * np.sqrt(p*(1-p)/n))\n",
    "ci = (p - margin, p + margin)\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952786f3-2976-4f61-adf9-a42b2ff3c27c",
   "metadata": {},
   "source": [
    "Compare it with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c6cbdc-777e-42ce-acc3-75c75e326469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfidenceInterval(low=0.7227997503290864, high=0.8633386747541124)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    stats.binomtest(k=80, n=100, alternative='two-sided')\n",
    "    .proportion_ci(confidence_level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c00d13-e207-4e03-a1b7-5e3cc5ea7700",
   "metadata": {},
   "source": [
    "#### (b) \n",
    "Find a 90% CI for the specifidty of the test, which is defined as the probability that a normal patient is correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e31362-da61-46f2-909d-d3f8c2e7f5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfidenceInterval(low=0.8810282256716788, high=0.9491782829700732)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    stats.binomtest(k=200-16, n=200, alternative='two-sided')\n",
    "    .proportion_ci(confidence_level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62c11f-dd28-4b24-868f-94424cbadd8d",
   "metadata": {},
   "source": [
    "### Ex 9.7\n",
    "\n",
    "People at high risk of sudden cardiac death can be identified using the change in a signal averaged electrocardiogram before and after prescribed activities. The current method is about 80% accurate. The method was modified, hoping to improve its accuracy. The new method is tested on 50 people and gave correct results on 46 patients. Is this convincing\n",
    "evidence that the new method is more accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b596d-6a6b-45ce-9d32-6232ba53fc95",
   "metadata": {},
   "source": [
    "#### (a) \n",
    "Set up the hypotheses to test that the accuracy of the new method is better than that of the current method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a51a6-b786-48e5-a68c-208e315f78e6",
   "metadata": {},
   "source": [
    "✍️ \n",
    "\n",
    "$$\n",
    "H_0: p = 0.8 \\quad \\text{v.s.} \\quad H_1: p > 0.8 .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f973fb-68b7-4786-be35-b6c884bcdca6",
   "metadata": {},
   "source": [
    "#### (b) \n",
    "Perform a test of the hypotheses at $\\alpha$ = .05. What do you conclude about the accuracy of the new method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6e6400-7081-4365-ba6b-2d4df04f11f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016947426762344633\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "p0 = 0.8\n",
    "p = 46/50\n",
    "z = (p - p0) / np.sqrt(p0*(1-p0)/n)\n",
    "pval = stats.norm.sf(z)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe8cff0-8bb7-4ee2-b640-8416f00e55c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018496015060209342\n"
     ]
    }
   ],
   "source": [
    "test = stats.binomtest(k=46, n=50, p=0.8, alternative='greater')\n",
    "print(test.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea914c-eb37-46a4-9a3d-5904b20cf2e5",
   "metadata": {},
   "source": [
    "The new method is significantly more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de834142-7519-4c3e-b4d1-906a3d5bbb55",
   "metadata": {},
   "source": [
    "### Ex 9.8\n",
    "\n",
    "Refer to the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba587e-7953-43ff-ba0f-9fb2ec398ab7",
   "metadata": {},
   "source": [
    "#### (a) \n",
    "If the new method actually has 90% accuracy, what power does a sample of 50 have to demonstrate that the new method is better, using a .05-level test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab79b7c-715f-4fc4-8fa7-d8ae9a5ef478",
   "metadata": {},
   "source": [
    "✍️ Knowing that $\\frac{\\hat{p} - p_1}{\\sqrt{p_1 q_1 / n}} \\sim N(0,1)$, the power\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\pi &= \\mathrm{P}\\left\\{\\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0 q_0}{n}}} > z_{\\alpha}\\right\\}\\\\\n",
    "&= \\mathrm{P}\\left\\{ \\frac{\\hat{p} - p_1}{\\sqrt{\\frac{p_1 q_1}{n}}} > \n",
    "    z_{\\alpha} \\sqrt{\\frac{p_0 q_0}{p_1 q_1}} + \\frac{p_0 - p_1}{\\sqrt{\\frac{p_1 q_1}{n}}} \\right\\} \\\\\n",
    "&= 1-\\Phi\\left( z_{\\alpha} \\sqrt{\\frac{p_0 q_0}{p_1 q_1}} + \\frac{p_0 - p_1}{\\sqrt{\\frac{p_1 q_1}{n}}}\\right) \\\\\n",
    "&= \\Phi\\left( \\frac{(p_1 - p_0) \\sqrt{n} - z_\\alpha \\sqrt{p_0 q_0}}{\\sqrt{p_1 q_1}} \\right) \\text{.}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2508ae1b-af37-4c5f-91cc-a93b6a3247aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5650889396286685\n"
     ]
    }
   ],
   "source": [
    "α = .05\n",
    "p0 = 0.8\n",
    "p1 = 0.9\n",
    "n = 50\n",
    "z = ((p1-p0)*math.sqrt(n) - stats.norm.ppf(1-α)*math.sqrt(p0*(1-p0))) / math.sqrt(p1*(1-p1))\n",
    "power = float(stats.norm.cdf(z))\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e37dc6-90e3-49f6-a0d4-4a7ee5153ebf",
   "metadata": {},
   "source": [
    "#### (b) \n",
    "How many patients should be tested in order for this power to be at least 0.75?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0fafa-76e1-462a-abf6-e444fbd270a7",
   "metadata": {},
   "source": [
    "✍️ Using the result from (a) and letting $\\pi = 0.75 = 1-\\beta$, we have\n",
    "\n",
    "$$\n",
    "\\frac{(p_1 - p_0) \\sqrt{n} - z_\\alpha \\sqrt{p_0 q_0}}{\\sqrt{p_1 q_1}} = z_{\\beta} \\text{,}\n",
    "$$\n",
    "\n",
    "therefore,\n",
    "\n",
    "$$\n",
    "n = \\left( \\frac{z_\\beta \\sqrt{p_1 q_1} + z_\\alpha \\sqrt{p_0 q_0}}{p_1 - p_0} \\right)^2 \\text{.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc2029f1-1e04-4bce-8e8c-fbfa8f65df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "β = 1 - 0.75\n",
    "n = ((stats.norm.ppf(1-β)*math.sqrt(p1*(1-p1)) + stats.norm.ppf(1-α)*math.sqrt(p0*(1-p0)))/(p0 - p1))**2\n",
    "print(np.ceil(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922ae34-5020-4272-8111-278429d95f88",
   "metadata": {},
   "source": [
    "### Ex 9.9\n",
    "\n",
    "A preelection poll is to be planned for a senatorial election between two candidates. Previous polls have shown that the election is hanging in delicate balance. If there is a shift (in either direction) by more than 2 percentage points since the last poll, then the polling agency would like to detect it with probability of at least 0.80 using a .05-level test. Determine how many voters should be polled. If actually 2500 voters are polled, what is the value of this probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc5d84-2d83-4613-9b5e-fdac6ebc07e2",
   "metadata": {},
   "source": [
    "✍️ We are considering the case when the real poll percentage is either > 52% or < 48%, but not both. So it is essentially the same as Ex. 9.8 except we should substitute $z_{\\alpha/2}$ for $z_\\alpha$ in the formula for $n$, giving\n",
    "\n",
    "$$\n",
    "n = \\left( \\frac{z_\\beta \\sqrt{p_1 q_1} + z_{\\alpha/2} \\sqrt{p_0 q_0}}{p_1 - p_0} \\right)^2 \\text{.}\n",
    "$$\n",
    "\n",
    "Note that for $p_1 = 1/2 \\pm \\delta$, the result would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9de519d-66cf-45f6-b383-aa8923070e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4904.0\n"
     ]
    }
   ],
   "source": [
    "β = 1 - 0.8\n",
    "α = .05\n",
    "p1 = 0.52 # or 0.48, the result will be the same.\n",
    "p0 = 0.5\n",
    "n = ((stats.norm.ppf(1-β)*math.sqrt(p1*(1-p1)) + stats.norm.ppf(1-α/2)*math.sqrt(p0*(1-p0)))/(p0 - p1))**2\n",
    "print(np.ceil(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81ba15-f645-4052-a5f5-f804e42af41e",
   "metadata": {},
   "source": [
    "If actually 2500 voters are polled, the power\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\pi &= \\mathrm{P}\\left\\{\\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0 q_0}{n}}} > z_{\\alpha/2}\\right\\}\n",
    "    + \\mathrm{P}\\left\\{\\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0 q_0}{n}}} < -z_{\\alpha/2}\\right\\}\\\\\n",
    "&= \\Phi\\left( \\frac{(p_1 - p_0) \\sqrt{n} - z_{\\alpha/2} \\sqrt{p_0 q_0}}{\\sqrt{p_1 q_1}} \\right)\n",
    "    + \\Phi\\left( \\frac{(p_0 - p_1) \\sqrt{n} - z_{\\alpha/2} \\sqrt{p_0 q_0}}{\\sqrt{p_1 q_1}} \\right) \\text{.}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533bf56-263b-4848-a7a2-d851acbe9ab0",
   "metadata": {},
   "source": [
    "Again, for $p_1 = 1/2 \\pm \\delta$, the result would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a51f36cb-c3a7-4b0d-897a-06fe8096ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5160175620301128\n"
     ]
    }
   ],
   "source": [
    "α = .05\n",
    "p0 = 0.5\n",
    "p1 = 0.52 # or 0.48, the result will be the same\n",
    "n = 2500\n",
    "z1 = ((p1-p0)*np.sqrt(n) - stats.norm.ppf(1-α/2)*np.sqrt(p0*(1-p0))) / np.sqrt(p1*(1-p1))\n",
    "z2 = ((p0-p1)*np.sqrt(n) - stats.norm.ppf(1-α/2)*np.sqrt(p0*(1-p0))) / np.sqrt(p1*(1-p1))\n",
    "power = float(stats.norm.cdf(z1) + stats.norm.cdf(z2))\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d62d7-575a-418c-9c88-4c89dca84bad",
   "metadata": {},
   "source": [
    "## 9.2 Inferences for Comparing Two Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec0625-eba7-473e-a4b9-9f063270ce1c",
   "metadata": {},
   "source": [
    "Next we consider the problem of comparing two Bernoulli proportions, $p_1$ and $p_2$, based on two independent random samples of sizes $n_1$ and $n_2$. The basis for inferences on $p_1 - p_2$ is the result that for large $n_1$ and $n_2$, the difference in the sample proportions, $\\hat{p}_1 - \\hat{p}_2$, is approximately normal with mean = $p_1 - p_2$ and standard deviation = $\\sqrt{p_1 q_1 / n_1 + p_2 q_2 / n_2}$ . A large sample two- sided 100(1 - $\\alpha$)% confidence interval for $p_1 - p_2$ is given by\n",
    "\n",
    "$$\n",
    "\\left[ \\hat{p}_1 - \\hat{p}_2 \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1 \\hat{q}_1}{n_1} + \\frac{\\hat{p}_2 \\hat{q}_2}{n_2}}\\; \\right].\n",
    "$$\n",
    "\n",
    "A large sample two-sided $z$-test can be used to test $H_0: p_1 = p_2$ vs. $H_1: p_1 \\ne  p_2$ by using the test statistic\n",
    "\n",
    "$$\n",
    "z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\frac{\\hat{p}_1 \\hat{q}_1}{n_1} + \\frac{\\hat{p}_2 \\hat{q}_2}{n_2}}}\n",
    "\\quad \\text{or} \\quad \n",
    "z = \\frac{\\hat{p}_1 - \\hat{p}_2}{\\sqrt{\\hat{p}\\hat{q}\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\hat{p} = (n_1\\hat{p}_1 + n_2\\hat{p}_2)/(n_1 + n_2)$ is the pooled sample proportion. Small sample tests to compare $p_1$ and $p_2$ are also given for independent samples (Fisher's exact test) and matched pairs designs (McNemar's test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a9669-feed-43f3-9d13-887427b69c8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ex 9.10\n",
    "\n",
    "To gauge a change in opinion regarding the public view on bilingual education, a telephone poll was taken in September 1993 and again in September 1995. The results based on the survey of 1000 American adults contacted in each poll were that 40% from the 1993 poll and 48% from the 1995 poll favored teaching all children in English over bilingual alternatives. Has there been a significant change in opinion? Answer by doing a two-sided test for the significance of the difference in two proportions at $\\alpha$ = .05. Why is a two-sided alternative appropriate here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee1b9b-9175-4a5c-8b9d-137adb0452ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ex 9.11\n",
    "\n",
    "A high school had 17 students receive National Merit recognition (semifinalist or commendation) out of 482 seniors in 1992 and 29 students out of 503 seniors in 1995. Does this represent a significant change in the proportion recognized at this school? Answer by doing a two-sided test for the significance of the difference in two proportions at $\\alpha$ = .10. Why is a two-sided alternative appropriate here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac58ea-dcd1-4b9e-8134-7acd971d4791",
   "metadata": {},
   "source": [
    "## 9.3 Inferences for One-way Count Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a4bdf-5a30-471d-bd18-d83d4e3c5190",
   "metadata": {},
   "source": [
    "A generalization of the test on the binomial proportion $p$ is a test on the cell probabilities of a multinomial distribution. Based on a random sample of size $n$ from a $c$-cell multinomial distribution (one-way count data) with cell probabilities $p_1, p_2, \\ldots, p_c$, the test of\n",
    "\n",
    "$$\n",
    "H_0: p_1 = p_{10},\\, p_2 = p_{20},\\, \\ldots, \\, p_c = p_{c0} \\quad \\text{vs.} \\quad\n",
    "H_1: \\text{At least one}\\, p_i \\ne p_{i0}\n",
    "$$\n",
    "\n",
    "is based on the **chi-square statistic** having the general form:\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(\\text{observed} - \\text{expected})^2}{\\text{expected}}\n",
    "$$\n",
    "\n",
    "where \"observed\" refers to the observed cell counts $n_i$ and \"expected\" refers to the expected cell counts $e_i = n p_{i0}$ under $H_0$. The degrees of freedom (d.f.) of the chi-square statistic are $c$ - 1. The primary use of this statistic is for the **goodness of fit** test of a specified distribution to a set of data. If any parameters of the distribution are estimated from the data, then one d.f. is deducted for each independent estimated parameter from the total d.f. $c$ - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84416064-4901-46c1-b4bb-400f2ac09253",
   "metadata": {},
   "source": [
    "## 9.4 Inferences for Two-way Count Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6551d-c13f-4a86-9a01-ea5ef1eadb1f",
   "metadata": {},
   "source": [
    "Two-way count data result when\n",
    "\n",
    "1. a single sample is cross-classified based on two categorical variables into $r$ rows and $c$ columns (**multinomial sampling**), or \n",
    "2. independent samples are drawn from $r$ multinomial distributions with the same $c$ categories\n",
    "(**product multinomial sampling**). \n",
    "\n",
    "In both cases, the data are summarized in the form of an $r \\times c$ **contingency table** of counts. In case (1), the null hypothesis of interest is the **independence hypothesis** between the row and column variables; in case (2), it is the **homogeneity hypothesis**. In both cases, the chi-square statistic has the same general form given above, with the expected count for the $(i, j)$th cell (under $H_0$) being the $i$th row total times the proportion of all observations falling in the $j$ th column. The d.f. of the chi-square statistic equal $(r - 1)(c - 1)$. Thus association between the row and the column variable is demonstrated at level $\\alpha$ if $\\chi^2 > \\chi^2_{(r-1)(c-1), \\alpha}$·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fa88d-a258-4591-abe0-e4614ce8d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
